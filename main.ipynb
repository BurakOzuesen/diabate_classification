{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBM409 - Introduction to Machine Learning Laboratory\n",
    "### Assignment 2: Diabetes Risk Prediction using Decision Tree\n",
    "### Atakan Yüksel - 21627892\n",
    "### Burak Özüesen - 21827761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation with k=5 will be used to evaluate our model. Instead of using traditional train_test_split, using k-fold cross validation is a better way to see how the model will handle unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(df): # k-fold cross validation with k=5\n",
    "\n",
    "    indices = np.arange(df.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    bucket_1 = []\n",
    "    bucket_2 = []\n",
    "    bucket_3 = []\n",
    "    bucket_4 = []\n",
    "    bucket_5 = []\n",
    "\n",
    "    for index, item in enumerate(indices):\n",
    "        if index % 5 == 0:\n",
    "            bucket_1.append(item)\n",
    "        elif index % 5 == 1:\n",
    "            bucket_2.append(item)\n",
    "        elif index % 5 == 2:\n",
    "            bucket_3.append(item)\n",
    "        elif index % 5 == 3:\n",
    "            bucket_4.append(item)\n",
    "        else:\n",
    "            bucket_5.append(item)\n",
    "    \n",
    "    df_subset_1 = df.iloc[bucket_1,:]\n",
    "    df_subset_2 = df.iloc[bucket_2,:]\n",
    "    df_subset_3 = df.iloc[bucket_3,:]\n",
    "    df_subset_4 = df.iloc[bucket_4,:]\n",
    "    df_subset_5 = df.iloc[bucket_5,:]\n",
    "\n",
    "    return [df_subset_1, df_subset_2, df_subset_3, df_subset_4, df_subset_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply discretization on \"Age\" column of our data. Decision Trees perform better on discrete data and discretization will be used on continuous columns. We will split \"Age\" into two bins. Higher bin counts cause an uneven distribution or lower accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization(data): # discretization on \"Age\" column of diabates_data. We are splitting into 2 bins. Higher bin numbers cause uneven distribution of \"Age\". Some bins end up with less than 5 examples while some bins have over 90.\n",
    "\n",
    "    max_age = np.amax(data[\"Age\"].to_numpy())\n",
    "    min_age = np.amin(data[\"Age\"].to_numpy())\n",
    "    \n",
    "    one_interval = (max_age - min_age) / 2\n",
    "    \n",
    "    first_bin = min_age + one_interval\n",
    "\n",
    "    bins = [min_age, first_bin, max_age]\n",
    "    temp = np.digitize(data[\"Age\"], bins) - 1\n",
    "    \n",
    "    \n",
    "    data[\"Age\"] = temp.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy and Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of Decision Trees (difference come from feature selection techniques). Since we are implementing a ID3 decision tree, we will use entropy and information gain for feature selection.<br>\n",
    "Entropy value of 0 means all samples belong to the same class, where entropy value of 1 means samples are distributed into classes equally.<br>\n",
    "Information gain of 1 means all samples belong to the same class, where information gain of 0 means the class distribution has not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "def entropy(pos, neg):\n",
    "    try:\n",
    "        return -((pos/(pos + neg)) * log2(pos/(pos + neg))) - ((neg/(pos + neg)) * log2(neg/(pos + neg)))\n",
    "    except ValueError: # either pos or neg is 0, which means there is no entropy, all the remaining values belong to same 'class'.\n",
    "        return 0\n",
    "    except ZeroDivisionError: # there are no positive or negative examples, so by returning 1, we are telling the build_decision_tree() function to ignore this attribute.\n",
    "        return 1\n",
    "\n",
    "assert str(entropy(9, 5))[:5] == \"0.940\" # example from lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(pos, neg, left_pos, left_neg, right_pos, right_neg):\n",
    "    def helper(t_pos, t_neg, h_pos, h_neg):\n",
    "        try:\n",
    "            return (t_pos + t_neg) / (t_pos + t_neg + h_pos + h_neg)\n",
    "        except ZeroDivisionError: # similar exception with entropy. there are no positive or negative examples so we are setting information gain to 0 to signal build_decision_tree() to ignore this attribute.\n",
    "            return 0\n",
    "\n",
    "    return entropy(pos, neg) - (helper(left_pos, left_neg, right_pos, right_neg) * entropy(left_pos, left_neg)) - (helper(right_pos, right_neg, left_pos, left_neg) * entropy(right_pos, right_neg))\n",
    "\n",
    "assert str(information_gain(9, 5, 3, 4, 6, 1))[:5] == \"0.151\" # example from lecture slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data = pd.read_csv(\"./data/diabetes_data_upload.csv\")\n",
    "diabetes_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying discretization on continuous \"Age\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization(diabetes_data) # apply discretization on \"Age\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing column data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    int64\n",
       "Gender                object\n",
       "Polyuria              object\n",
       "Polydipsia            object\n",
       "sudden weight loss    object\n",
       "weakness              object\n",
       "Polyphagia            object\n",
       "Genital thrush        object\n",
       "visual blurring       object\n",
       "Itching               object\n",
       "Irritability          object\n",
       "delayed healing       object\n",
       "partial paresis       object\n",
       "muscle stiffness      object\n",
       "Alopecia              object\n",
       "Obesity               object\n",
       "class                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data.dtypes # since all the answers are binary no need to have object datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all columns to category as they are binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                   category\n",
       "Gender                category\n",
       "Polyuria              category\n",
       "Polydipsia            category\n",
       "sudden weight loss    category\n",
       "weakness              category\n",
       "Polyphagia            category\n",
       "Genital thrush        category\n",
       "visual blurring       category\n",
       "Itching               category\n",
       "Irritability          category\n",
       "delayed healing       category\n",
       "partial paresis       category\n",
       "muscle stiffness      category\n",
       "Alopecia              category\n",
       "Obesity               category\n",
       "class                 category\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in diabetes_data.columns: # converting columns to category.\n",
    "    diabetes_data[column] = diabetes_data[column].astype(\"category\")\n",
    "diabetes_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all answers to 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  Polyphagia  \\\n",
       "0   0       0         0           1                   0         1           0   \n",
       "1   1       0         0           0                   0         1           0   \n",
       "2   0       0         1           0                   0         1           1   \n",
       "\n",
       "   Genital thrush  visual blurring  Itching  Irritability  delayed healing  \\\n",
       "0               0                0        1             0                1   \n",
       "1               0                1        0             0                0   \n",
       "2               0                0        1             0                1   \n",
       "\n",
       "   partial paresis  muscle stiffness  Alopecia  Obesity  class  \n",
       "0                0                 1         1        1      1  \n",
       "1                1                 0         1        0      1  \n",
       "2                0                 1         1        0      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in diabetes_data.columns: # converting string answers to 0 and 1.\n",
    "    if column != \"Age\":\n",
    "        diabetes_data[column] = diabetes_data[column].replace(to_replace=[\"No\", \"Yes\", \"Negative\", \"Positive\", \"Male\", \"Female\"], value=[0, 1, 0, 1, 0, 1])\n",
    "diabetes_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering 5 folds for cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subsets = cross_validation(diabetes_data) # 5-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Node class as a building block for the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: # this is a node in the decision tree. It stores it's name, it's neigbors(childs), what the prediction would be if decision tree stopped here, and the information gain achieved by this node.\n",
    "    def __init__(self, name, neigbors, pred, information_gain):\n",
    "        self._name = name\n",
    "        self._neigbors = neigbors\n",
    "        self._prediction = pred\n",
    "        self._information_gain = information_gain\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self._name = name\n",
    "\n",
    "    def get_neighbors(self):\n",
    "        return self._neigbors\n",
    "\n",
    "    def set_neighbors(self, neighbors): # this function is used to remove childs from a twig.\n",
    "        self._neigbors = neighbors\n",
    "    \n",
    "    def add_neighbor(self, neighbor):\n",
    "        self._neigbors.append(neighbor)\n",
    "\n",
    "    def get_prediction(self):\n",
    "        return self._prediction   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, level=0):\n",
    "    try:\n",
    "        leftChild = node.get_neighbors()[0]\n",
    "        rightChild = node.get_neighbors()[1]\n",
    "        print_tree(rightChild, level + 1)\n",
    "        print(\" \" * 4 * level + \"->\", node.get_name())\n",
    "        print_tree(leftChild, level + 1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function build_decision_tree(df, root, target=\"class\") takes 3 arguments. df is the training dataframe the model will train on, root is the starting Node of the decision tree, and target is the column name we are trying to predict. Function does not calculate the root on its own, so the root must be calculated beforehand and fed to the function.<br>Comments explain the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(df, root, target=\"class\"):\n",
    "    if len(df.columns) == 2: # only 'class' column is left\n",
    "        return\n",
    "\n",
    "    # since all the answers are binary we are building two branches where the answer is 0 and 1 respectively.\n",
    "\n",
    "    # left branch\n",
    "    left_branch = df[df[root.get_name()] == 0].copy(deep=True)\n",
    "    left_branch.drop(columns=[root.get_name()], inplace=True)\n",
    "\n",
    "    if left_branch.shape[0] == 0: # there are cases where some attributes are not used when there are no more rows left to process. In these cases we stop.\n",
    "        return\n",
    "\n",
    "    left_ig_dict = {} # this is used to store information gains for columns in str(column_name) : int(information_gain) format.\n",
    "    for column in left_branch.columns:\n",
    "        if column != target:\n",
    "            neg_df = left_branch[left_branch[column] == 0] # the branch where the respective column is all 0s\n",
    "            pos_df = left_branch[left_branch[column] == 1] # the branch where the respective column is all 1s\n",
    "\n",
    "            left_ig_dict[column] = information_gain(len(left_branch[left_branch[target] == 1]), len(left_branch[left_branch[target] == 0]), len(neg_df[neg_df[target] == 1]), len(neg_df[neg_df[target] == 0]), len(pos_df[pos_df[target] == 1]), len(pos_df[pos_df[target] == 0]))\n",
    "    \n",
    "    left_index_max = np.argmax(list(left_ig_dict.values())) # since we store information gains in a dictionary, getting the maximum value is not straightforward.\n",
    "    left_selected_feature = left_branch.columns[left_index_max]\n",
    "    \n",
    "    pred_index = np.argmax(left_branch[target].value_counts().to_dict().values()) # this where we know what the prediction would be if the decision tree stopped at this node. we are getting the counts of 0s and 1s and pick the prediction that occurs more.\n",
    "    prediction = list(left_branch[target].value_counts().to_dict().keys())[pred_index]\n",
    "\n",
    "    left_node = Node(left_selected_feature, [], prediction, left_ig_dict[left_selected_feature]) # constructing the node.\n",
    "    root.add_neighbor(left_node) # adding a child.\n",
    "\n",
    "    build_decision_tree(left_branch, left_node) # recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\n",
    "\n",
    "\n",
    "    # same that happen with left branch happen here also. the difference is now the respective attribute is equal to 1.\n",
    "    # right branch\n",
    "    right_branch = df[df[root.get_name()] == 1].copy(deep=True)\n",
    "    right_branch.drop(columns=[root.get_name()], inplace=True)\n",
    "\n",
    "    if right_branch.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    right_ig_dict = {}\n",
    "    for column in right_branch.columns:\n",
    "        if column != target:\n",
    "            neg_df = right_branch[right_branch[column] == 0]\n",
    "            pos_df = right_branch[right_branch[column] == 1]\n",
    "\n",
    "            right_ig_dict[column] = information_gain(len(right_branch[right_branch[target] == 1]), len(right_branch[right_branch[target] == 0]), len(neg_df[neg_df[target] == 1]), len(neg_df[neg_df[target] == 0]), len(pos_df[pos_df[target] == 1]), len(pos_df[pos_df[target] == 0]))\n",
    "    \n",
    "    right_index_max = np.argmax(list(right_ig_dict.values()))\n",
    "    right_selected_feature = right_branch.columns[right_index_max]\n",
    "\n",
    "    pred_index = np.argmax(right_branch[target].value_counts().to_dict().values())\n",
    "    prediction = list(right_branch[target].value_counts().to_dict().keys())[pred_index]\n",
    "    \n",
    "    right_node = Node(right_selected_feature, [], prediction, right_ig_dict[right_selected_feature])\n",
    "    root.add_neighbor(right_node)\n",
    "\n",
    "    build_decision_tree(right_branch, right_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we construct 5 decision trees for 5 different folds. As previously stated, root is being fed to the function.<br>Comments explain the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3843/3499840892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0md_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# creating the root.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_root\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# time to create the tree with d_root as its root node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_root\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# store the root in trees for classification metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adding a child.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adding a child.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adding a child.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adding a child.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adding a child.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adding a child.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_node\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# recursive call. by design the decision tree will try to build all left branches until it can't since we always call left branch before right branch in every recursive call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3843/3933680011.py\u001b[0m in \u001b[0;36mbuild_decision_tree\u001b[0;34m(df, root, target)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mpos_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mright_branch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mright_ig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_branch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mright_index_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_ig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bbm409_assignment2/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bbm409_assignment2/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bbm409_assignment2/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bbm409_assignment2/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minvalid_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_fill_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bbm409_assignment2/lib/python3.8/site-packages/pandas/core/ops/missing.py\u001b[0m in \u001b[0;36mdispatch_fill_zeros\u001b[0;34m(op, left, right, result)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfill_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         )\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloordiv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Note: no need to do this for truediv; in py3 numpy behaves the way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m#  we want.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating trees for each fold.\n",
    "\n",
    "trees = []\n",
    "\n",
    "for i in data_subsets: # data_subsets contain folds\n",
    "    training_df = diabetes_data.drop(list(i.index.values)) # we remove folds from the main dataframe.\n",
    "\n",
    "    target = \"class\"\n",
    "    gains = {}\n",
    "\n",
    "    for column in training_df.columns[:-1]: # not interested in 'class' column\n",
    "        neg_df = training_df[training_df[column] == 0] # all negatives\n",
    "        pos_df = training_df[training_df[column] == 1] # all positives\n",
    "\n",
    "        gains[column] = information_gain(len(training_df[training_df[target] == 1]), len(training_df[training_df[target] == 0]), len(neg_df[neg_df[target] == 1]), len(neg_df[neg_df[target] == 0]), len(pos_df[pos_df[target] == 1]), len(pos_df[pos_df[target] == 0]))\n",
    "\n",
    "    max_index = np.argmax(list(gains.values()))\n",
    "    selection = training_df.columns[max_index] # we selected our root node.\n",
    "\n",
    "    d_root = Node(selection, [], 0, 1) # creating the root.\n",
    "\n",
    "    build_decision_tree(training_df, d_root) # time to create the tree with d_root as its root node.\n",
    "\n",
    "    trees.append(d_root) # store the root in trees for classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the prediction happens for each fold. We see the classification results for each fold.<br>Comments explain the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where we see the classification results for the model. this is also where the prediction happens.\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 3))\n",
    "\n",
    "misclassified_samples = [[], [], [], [], []]\n",
    "\n",
    "\n",
    "for tree_index, data_subset in enumerate(data_subsets): # for every fold.\n",
    "\n",
    "    test_df = data_subset\n",
    "    training_tree = trees[tree_index]\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for index, row in test_df.iterrows(): # for every row in the fold\n",
    "        current_node = training_tree # root starting point\n",
    "        while True:\n",
    "            try:\n",
    "                next_node = current_node.get_neighbors()[row[current_node.get_name()]] # row[current_node.get_name()] is either 0 and 1. if its 0 go to the left branch, it its 1 go to the right branch.\n",
    "                current_node = next_node\n",
    "            except: # we reached the end of the tree.\n",
    "                y_true.append(row[\"class\"])\n",
    "                y_pred.append(current_node.get_prediction())\n",
    "                if row[\"class\"] != current_node.get_prediction():\n",
    "                    misclassified_samples[tree_index].append(row)\n",
    "                break\n",
    "\n",
    "    print(\"Classification Metrics for Fold #{}\".format(tree_index + 1))\n",
    "    print(classification_report(y_true, y_pred) + \"\\n\")\n",
    "\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    axes[tree_index].set_title(\"Fold #{}\".format(tree_index + 1))\n",
    "    sns.heatmap(ax=axes[tree_index], data=cf_matrix, annot=labels, fmt=\"\", cmap='Blues', vmin=0, vmax=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold #1 has the highest f1 scores for \"Negative\" and \"Positive\" class values, it also has highest precision for \"Negative\" and highest recall for \"Positive\"\n",
    "\n",
    "Fold #2 #3 #4 are neither the best in any categories or the worst.\n",
    "\n",
    "Fold #5 has the highest precision for \"Positive\" and highest recall for \"Negative\"\n",
    "\n",
    "Since Fold #1 has the highest f1 scores, it is our best tree model.\n",
    "\n",
    "Below is the visualization of Fold #1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(trees[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some misclassified samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(misclassified_samples):\n",
    "    print(\"Misclassified Sample for Fold #{}\".format(index + 1))\n",
    "    print(item[0], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st, 3rd, 4th samples have \"partial paresis\" == 1, which seems to be common among misclassified samples.\n",
    "2nd misclassified sample could be an edge case.\n",
    "5th misclassified sample only has \"Gender\" == 1, other features are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees tend to overfit a lot. There are multiple ways to tackle this problem like setting a maximum depth, ignoring information gains below a threshold, pruning etc. For this assignment, we will utilize pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into 60-20-20 percents as train_df, test_df and validation_df respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df): # train test val split with percentages 60-20-20 respectively.\n",
    "    indices = np.arange(df.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_bucket = []\n",
    "    test_bucket = []\n",
    "    validation_bucket = []\n",
    "\n",
    "    for index, item in enumerate(indices):\n",
    "        if index % 5 in [0,1,2]:\n",
    "            train_bucket.append(item)\n",
    "        elif index % 5 == 3:\n",
    "            test_bucket.append(item)\n",
    "        elif index % 5 == 4:\n",
    "            validation_bucket.append(item)\n",
    "\n",
    "    \n",
    "    train_df = df.iloc[train_bucket,:]\n",
    "    test_df = df.iloc[test_bucket,:]\n",
    "    validation_df = df.iloc[validation_bucket,:]\n",
    "\n",
    "    return train_df, test_df, validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step is the same with previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, validation_df = train_test_val_split(diabetes_data) # splitting the main dataframe\n",
    "\n",
    "target = \"class\"\n",
    "gains = {}\n",
    "\n",
    "for column in train_df.columns[:-1]: # not interested in 'class' column\n",
    "    neg_df = train_df[train_df[column] == 0] # only the rows where column = 0\n",
    "    pos_df = train_df[train_df[column] == 1] # only the rows where column = 1\n",
    "\n",
    "    gains[column] = information_gain(len(train_df[train_df[target] == 1]), len(train_df[train_df[target] == 0]), len(neg_df[neg_df[target] == 1]), len(neg_df[neg_df[target] == 0]), len(pos_df[pos_df[target] == 1]), len(pos_df[pos_df[target] == 0]))\n",
    "\n",
    "max_index = np.argmax(list(gains.values()))\n",
    "selection = train_df.columns[max_index] # selecting the feature with the highest information gain.\n",
    "\n",
    "d_root = Node(selection, [], 0, 1)\n",
    "\n",
    "build_decision_tree(train_df, d_root) # training the decision tree on train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Metrics for the trained tree on test_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification results on the test_df\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for index, row in test_df.iterrows(): \n",
    "    current_node = d_root\n",
    "    while True:\n",
    "        try:\n",
    "            next_node = current_node.get_neighbors()[row[current_node.get_name()]]\n",
    "            current_node = next_node\n",
    "        except:\n",
    "            y_true.append(row[\"class\"])\n",
    "            y_pred.append(current_node.get_prediction())\n",
    "            break\n",
    "\n",
    "print(\"Classification Metrics for 60-20-20 train-test-val split on test_df:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(data=cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Metrics for the trained tree on validation_df before pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification results on the validation_df before pruning\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for index, row in validation_df.iterrows(): \n",
    "    current_node = d_root\n",
    "    while True:\n",
    "        try:\n",
    "            next_node = current_node.get_neighbors()[row[current_node.get_name()]]\n",
    "            current_node = next_node\n",
    "        except:\n",
    "            y_true.append(row[\"class\"])\n",
    "            y_pred.append(current_node.get_prediction())\n",
    "            break\n",
    "\n",
    "print(\"Classification Metrics for 60-20-20 train-test-val split on validation_df before pruning:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(data=cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruleset before pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(d_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Metrics for the trained tree on validation_df after pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for index, row in validation_df.iterrows(): \n",
    "    current_node = d_root # d_root is the root of the decision tree.\n",
    "    while True:\n",
    "        try:\n",
    "            if len(current_node.get_neighbors()) == 1: # found a twig\n",
    "                current_node.set_neighbors([]) # removing childs of the twig\n",
    "                y_true.append(row[\"class\"])\n",
    "                y_pred.append(current_node.get_prediction())\n",
    "                break\n",
    "            next_node = current_node.get_neighbors()[row[current_node.get_name()]]\n",
    "            current_node = next_node\n",
    "        except: # reached the end of the tree\n",
    "            y_true.append(row[\"class\"])\n",
    "            y_pred.append(current_node.get_prediction())\n",
    "            break\n",
    "\n",
    "print(\"Classification Metrics for 60-20-20 train-test-val split on validation_df after pruning:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(data=cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruleset after pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(d_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the initial accuracy is too high, pruning is ineffective for this dataset."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea42d00d1a78575049f31183f53a409ed770363d4151e5a5d3246bbbad414526"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('bbm409_assignment2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
